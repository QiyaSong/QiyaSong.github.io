---
permalink: /
title: "Welcome to Qiya Song’s homepage!"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

-  宋启亚，工学博士，**硕士研究生导师，师从李树涛教授，2023年毕业于湖南大学电气与信息工程学院/机器人视觉感知与国家工程研究中心（主任：王耀南院士）**，2024年入职于湖南师范大学信息科学与工程学院。以第一/通讯作者在IEEE TNNLS、ACM Multimedia等高水平国际期刊/会议发表论文多篇，论文发表获得到国内外同行的关注，申请/授权发明专利五项（其中一项已经完成成果转换）。

- 在国际顶级会议ACL、ACM以及全球最大竞赛平台kaggle上举办的国际竞赛获得冠军4项、亚军2项；获得国际“互联网+” 创新创业大赛全国银奖/铜奖等；作为研究骨干参与国家重点研发、JKW等国家级/省部级项目多项，与等国内外知名企业和技术企业保持良好合作关系。长期担任IEEE TNNLS、IEEE TALSP IEEE TMM等国内外期刊的审稿人以及多个专委会执行委员，先后获得湖南大学校长奖学金、湖南大学优秀研究生等荣誉称号。

- **<font color=blue> 联系方式(微信号)：QiyS_UNB （如有需求，请注明来意）</font>**

 - **<font color=blue>Email：sqyunb@hnu.edu.cn</font>**

# 🔥 Researches
**长期从事多模态信息融合、音视频图像处理、人工智能、深度学习技术等研究；主要如下：**

-**（1）多模图像融合：**多模图像融合能利用不同模态的优势，实现更全面、更清晰、更准确的感知，在军事侦察、遥感测绘、医疗诊断等领域发挥重要作用。

<center>
    <img style = "
        border-radius: 0.3125em;
        box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
        src = 'images/多模态图像融合.png'
        width = "80%">
    <br />
    <div style = "
        color: orange;
        border-bottom: 1px solid #d9d9d9;
        display: inline-block;
        color: #999;
        padding: 2px;">
    </div>
    <p> </p>
</center>

-**（2）多模态融合的机器人自然交互：**针对复杂场景下人机交互系统面临的智能化和情感化挑战，发展多模信息融合（语音、视觉、文本等）的理论方法，攻克智能人机交互技术。


<center>
    <img style = "
        border-radius: 0.3125em;
        box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
        src = 'images/多模态人机交互.png'
        width = "80%">
    <br />
    <div style = "
        color: orange;
        border-bottom: 1px solid #d9d9d9;
        display: inline-block;
        color: #999;
        padding: 2px;">
    </div>
    <p> </p>
</center>



- *2022.02*: &nbsp;🎉🎉 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;🎉🎉 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# 📝 Academics

**Publications (Last three years)**
- Multi-modal Sparse Transformer Network for Audio-Visual Speech Recognition, IEEE Transactions on Neural Networks and Learning Systems, 2022, doi:10.1109/TNNLS.2022.3163771 （SCI中科院一区 TOP期刊 IF=14.25）
- Multi-scale Conformer Fusion Network for Multi-participant Behavior Analysis. Proceedings of the 31st ACM International Conference on Multimedia. 2023.（国际多媒体顶级会议 CCF_A类会议）
- Multi-modal Joint Learning framework with Modality Interaction Network for robust speech recognition, in Information Fusion，under review（SCI中科院一区 TOP期刊 IF=18.60）
- Continuing Pre-trained Model with Multiple Training Strategies for Emotional Classification，Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis @ ACL. 2022（CCF_A workshop , EI ）
- Prompt-based Pre-trained Model for Personality and Interpersonal Reactivity Prediction，Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis @ ACL. 2022 （CCF_A workshop , EI ）
- Artificial	Text	Detection	with	Multiple	Training	Strategies，	Computational	Linguistics and	Intellectual	Technologies:	Proceedings	of	the	International	Conference	（EI	会议）


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# 💻Projects
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.

# 🎖 Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

